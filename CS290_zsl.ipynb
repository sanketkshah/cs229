{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version:  1.8.1\n",
      "Torchvision Version:  0.9.1\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "from __future__ import division\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import copy\n",
    "import sys\n",
    "from imagenetv2_pytorch import ImageNetV2Dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy.spatial.distance import cosine\n",
    "from pytorch_metric_learning import losses\n",
    "import wandb\n",
    "\n",
    "print(\"PyTorch Version: \",torch.__version__)\n",
    "print(\"Torchvision Version: \",torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def initialize_model(model_name, embedding_dim, feature_extract, use_pretrained=True):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "\n",
    "    if \"resnet\" in model_name:\n",
    "        \"\"\" Resnet18\n",
    "        \"\"\"\n",
    "        if model_name == \"beefyresnet\":\n",
    "            num_layers = 3\n",
    "        elif model_name == \"verybeefyresnet\":\n",
    "            num_layers = 5\n",
    "        else:\n",
    "            num_layers = 1\n",
    "\n",
    "        model_ft = models.resnet18(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "        if num_layers > 1:\n",
    "            model_ft.fc = nn.Linear(num_ftrs, num_ftrs)\n",
    "            for _ in range(num_layers - 2):\n",
    "                model_ft = nn.Sequential(\n",
    "                    model_ft,\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(num_ftrs, num_ftrs)\n",
    "                )\n",
    "            model_ft = nn.Sequential(\n",
    "                    model_ft,\n",
    "                    nn.ReLU(),\n",
    "                    nn.Linear(num_ftrs, embedding_dim)\n",
    "                )\n",
    "        else:\n",
    "            model_ft.fc = nn.Linear(num_ftrs, embedding_dim)\n",
    "            \n",
    "        input_size = 224\n",
    "\n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        sys.exit(0)\n",
    "    \n",
    "    return model_ft, input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst = [\"imagenetv2\", \"cifar10\"]\n",
    "losses=[\"cliplossv2\", \"cliploss\", \"cosineloss\", \"xeloss\"]\n",
    "embeddings=[\"onehot\", \"label\", \"wiki\", \"clip\"]\n",
    "networks = [\"resnet\", \"beefyresnet\", \"verybeefyresnet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_labelembedding(image_embeddings, label_embeddings):\n",
    "    return (image_embeddings @ label_embeddings.T).argmax(-1)\n",
    "\n",
    "\n",
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_a(wnid, group_wnids, imagenet_ancestors):\n",
    "    r = False\n",
    "    for g_wnid in group_wnids:\n",
    "        if g_wnid in imagenet_ancestors[wnid]:\n",
    "            r = True\n",
    "    return r\n",
    "\n",
    "def sparse2coarse(targets):\n",
    "    \"\"\"Convert Pytorch CIFAR100 sparse targets to coarse targets.\n",
    "    Usage:\n",
    "        trainset = torchvision.datasets.CIFAR100(path)\n",
    "        trainset.targets = sparse2coarse(trainset.targets)\n",
    "    \"\"\"\n",
    "    coarse_labels = np.array([ 4,  1, 14,  8,  0,  6,  7,  7, 18,  3,  \n",
    "                               3, 14,  9, 18,  7, 11,  3,  9,  7, 11,\n",
    "                               6, 11,  5, 10,  7,  6, 13, 15,  3, 15,  \n",
    "                               0, 11,  1, 10, 12, 14, 16,  9, 11,  5, \n",
    "                               5, 19,  8,  8, 15, 13, 14, 17, 18, 10, \n",
    "                               16, 4, 17,  4,  2,  0, 17,  4, 18, 17, \n",
    "                               10, 3,  2, 12, 12, 16, 12,  1,  9, 19,  \n",
    "                               2, 10,  0,  1, 16, 12,  9, 13, 15, 13, \n",
    "                              16, 19,  2,  4,  6, 19,  5,  5,  8, 19, \n",
    "                              18,  1,  2, 15,  6,  0, 17,  8, 14, 13])\n",
    "    return coarse_labels[targets]\n",
    "\n",
    "# Data augmentation and normalization for training, just normalization for validation\n",
    "def create_dataloaders(dataset_name, data_transforms, input_size, batch_size):\n",
    "    \n",
    "    dataloaders_dict = {}\n",
    "\n",
    "    print(\"Initializing Datasets and Dataloaders...\")\n",
    "    if dataset_name == \"imagenetv2\" or dataset_name == \"imagenetv2coarse\":\n",
    "        # Create training and validation datasets\n",
    "        train_dataset = ImageNetV2Dataset(transform=data_transforms['train'])\n",
    "        test_dataset = ImageNetV2Dataset(transform=data_transforms['val'])\n",
    "\n",
    "        train_test_splits_file = 'split_indices.pkl'\n",
    "\n",
    "        if os.path.exists(train_test_splits_file):\n",
    "            indices_split = pickle.load(open(train_test_splits_file, 'rb'))\n",
    "        else:\n",
    "            index_to_class = {idx: cl for idx, (_, cl) in enumerate(train_dataset)}\n",
    "            class_to_index = {idx: [] for idx in range(1000)}\n",
    "            for idx, cl in index_to_class.items():\n",
    "                class_to_index[cl].append(idx)\n",
    "\n",
    "            indices_split = {'train': [], 'val': [], 'test': []}\n",
    "            for cl in class_to_index:\n",
    "                shuffle(class_to_index[cl])\n",
    "                indices_split['train'].extend(class_to_index[cl][:int(0.7 * len(class_to_index[cl]))])\n",
    "                indices_split['val'].extend(class_to_index[cl][int(0.7 * len(class_to_index[cl])):int(0.9 * len(class_to_index[cl]))])\n",
    "                indices_split['test'].extend(class_to_index[cl][int(0.9 * len(class_to_index[cl])):])\n",
    "            \n",
    "            pickle.dump(indices_split, open(train_test_splits_file, 'wb'))\n",
    "            \n",
    "\n",
    "        # Create training and validation dataloaders\n",
    "        dataloaders_dict = {x: torch.utils.data.DataLoader(Subset(test_dataset,indices_split[x]), batch_size=batch_size, shuffle=True, num_workers=4) for x in ['val', 'test']}\n",
    "        dataloaders_dict['train'] = torch.utils.data.DataLoader(Subset(train_dataset, indices_split['train']), batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    else:\n",
    "        if dataset_name == \"imagenet\":\n",
    "            train_dataset = torchvision.datasets.ImageNet(root='./data', split='train', download=True, transform=data_transforms['train'])\n",
    "            test_dataset = torchvision.datasets.ImageNet(root='./data', split='val', download=True, transform=data_transforms['val'])\n",
    "        elif dataset_name == \"cifar10\":\n",
    "            train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=data_transforms['train'])\n",
    "            test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=data_transforms['val'])\n",
    "        elif dataset_name == \"cifar100\":\n",
    "            train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=data_transforms['train'])\n",
    "            test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=data_transforms['val'])\n",
    "        elif dataset_name == \"cifar100super\":\n",
    "            train_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=data_transforms['train'])\n",
    "            train_dataset.targets = sparse2coarse(train_dataset.targets)\n",
    "            test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=data_transforms['val'])\n",
    "            test_dataset.targets = sparse2coarse(test_dataset.targets)\n",
    "        else:\n",
    "            print(\"Error dataset not found\")\n",
    "            sys.exit(0)\n",
    "\n",
    "        dataloaders_dict['train'] = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "        dataloaders_dict['val'] = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "    return dataloaders_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_label_embeddings(embedding_type, embedding_dim, dataset_name):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if embedding_type == \"onehot\":\n",
    "        # One-hot text embeddings\n",
    "        label_embeddings = torch.from_numpy(np.eye(embedding_dim, dtype=np.float32)).to(device)\n",
    "    else:\n",
    "        model = SentenceTransformer('paraphrase-distilroberta-base-v1')\n",
    "        # Load labeltext\n",
    "        \n",
    "        if dataset_name == \"imagenet\" or dataset_name == \"imagenetv2\" or dataset_name == \"imagenetv2coarse\":\n",
    "            classidx_to_label = pickle.load(open('classidx_to_label.pkl', 'rb'))\n",
    "        elif dataset_name == \"cifar10\":\n",
    "            classidx_to_label = pickle.load(open('./data/cifar-10-batches-py/batches.meta', 'rb'))['label_names']\n",
    "        elif dataset_name == \"cifar100\":\n",
    "            classidx_to_label = pickle.load(open('./data/cifar-100-python/meta', 'rb'))['fine_label_names']\n",
    "        elif dataset_name == \"cifar100super\":\n",
    "            classidx_to_label = pickle.load(open('./data/cifar-100-python/meta', 'rb'))\n",
    "\n",
    "            coarse = classidx_to_label['coarse_label_names']\n",
    "            fine = classidx_to_label['fine_label_names']\n",
    "            classidx_to_label = []\n",
    "\n",
    "            for i in range(len(coarse)):\n",
    "                classidx_to_label.append('')\n",
    "\n",
    "            for i in range(len(fine)):\n",
    "                if classidx_to_label[sparse2coarse(i)] == '':\n",
    "                    classidx_to_label[sparse2coarse(i)] = str(fine[i])\n",
    "                else:\n",
    "                    classidx_to_label[sparse2coarse(i)] += \" or \" + str(fine[i])\n",
    "        else:\n",
    "            print(\"ERROR: Dataset without labels\")\n",
    "            return None\n",
    "        \n",
    "        if embedding_type == \"label\":\n",
    "            # Text embeddings based on class label text\n",
    "            if dataset_name == \"imagenet\" or dataset_name == \"imagenetv2\" or dataset_name == \"imagenetv2coarse\":\n",
    "                labels = list(classidx_to_label.values())\n",
    "            else:\n",
    "                labels = list(classidx_to_label)\n",
    "                \n",
    "        elif embedding_type == 'wiki':\n",
    "            if dataset_name == \"imagenet\" or dataset_name == \"imagenetv2\" or dataset_name == \"imagenetv2coarse\":\n",
    "                # Load wikitext\n",
    "                wiki_path = 'ImageNet-Wiki_dataset/class_article_text_descriptions/class_article_text_descriptions_trainval.pkl'\n",
    "                wiki_articles = pickle.load(open(wiki_path, 'rb'))\n",
    "                wiki_label_map = pd.read_csv('LOC_synset_mapping.txt', sep=': ', names=['wnid', 'labels'])\n",
    "\n",
    "\n",
    "                wiki_labels = {}\n",
    "                for i in classidx_to_label.keys():\n",
    "                    wiki_labels[wiki_label_map.iloc[i]['wnid']] = classidx_to_label[i]\n",
    "\n",
    "                for i in wiki_articles.keys():\n",
    "                    try:\n",
    "                        wiki_labels[wiki_articles[i]['wnid']] = wiki_articles[i]['articles'][0]\n",
    "                    except:\n",
    "                        pass\n",
    "                labels = list(wiki_labels.values())\n",
    "            else:\n",
    "                return None\n",
    "        elif embedding_type == 'clip':\n",
    "            # Text embeddings based on class label text\n",
    "            clip_labels={}\n",
    "            if dataset_name == \"imagenet\" or dataset_name == \"imagenetv2\" or dataset_name == \"imagenetv2coarse\":\n",
    "                for i in classidx_to_label.keys():\n",
    "                    clip_labels[i] = 'A photo of ' + str(classidx_to_label[i].split(\",\")[0].rstrip().lstrip())\n",
    "            else:\n",
    "                for i in range(len(classidx_to_label)):\n",
    "                    clip_labels[i] = 'A photo of ' + str(classidx_to_label[i].split(\",\")[0].rstrip().lstrip())\n",
    "            labels = list(clip_labels.values())\n",
    "\n",
    "        label_embeddings = torch.from_numpy(model.encode(labels)).to(device)\n",
    "        label_embeddings = label_embeddings / label_embeddings.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    return label_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def morph_labels_imagenetv2(inputlabels):\n",
    "    \n",
    "    ancestor_label_file = 'imagenetv2_ancestor.pkl'\n",
    "    \n",
    "    if os.path.exists(ancestor_label_file):\n",
    "        labels = pickle.load(open(ancestor_label_file, 'rb'))\n",
    "    else:\n",
    "        classidx_to_label = pickle.load(open('classidx_to_label.pkl', 'rb'))\n",
    "        imagenet_ancestors = pickle.load(open('imagenet_wordnet_ancestor_categories.pkl', 'rb'))\n",
    "\n",
    "        wnid_animals = ['n00015388']\n",
    "        wnid_plants = ['n00017222', 'n07707451', 'n13134947']\n",
    "\n",
    "        label_map = pd.read_csv('LOC_synset_mapping.txt', sep=': ', names=['wnid', 'labels'])\n",
    "\n",
    "        ancestor_labels = {}\n",
    "        for i in classidx_to_label.keys():\n",
    "            wnid = label_map.iloc[i]['wnid']\n",
    "\n",
    "            if is_a(wnid, wnid_animals, imagenet_ancestors):\n",
    "                ancestor_labels[wnid] = 0\n",
    "            elif is_a(wnid, wnid_plants, imagenet_ancestors):\n",
    "                ancestor_labels[wnid] = 1\n",
    "            else:\n",
    "                ancestor_labels[wnid] = 2\n",
    "        \n",
    "        labels = list(ancestor_labels.values())\n",
    "\n",
    "        pickle.dump(labels, open(ancestor_label_file, 'wb'))\n",
    "    \n",
    "    result = []\n",
    "    for i in inputlabels:\n",
    "        result.append(labels[i])\n",
    "    return result\n",
    "\n",
    "def morph_labels_cifar100(inputlabels):\n",
    "    result = []\n",
    "    for i in inputlabels:\n",
    "        result.append(sparse2coarse(i))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zsl_test(model, testloader, label_embeddings=None, embedding_to_label=None, morph_labels=None):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    running_corrects = 0\n",
    "    total_num = 0\n",
    "    for inputs, labels in testloader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outputs = model(inputs)      \n",
    "        outputs = outputs / outputs.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        if embedding_to_label is not None and label_embeddings is not None:\n",
    "            preds = embedding_to_label(outputs, label_embeddings)\n",
    "        else:\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        # statistics\n",
    "        if morph_labels is None:\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "        else:\n",
    "            labels = morph_labels(labels.data)\n",
    "            preds = morph_labels(preds)\n",
    "            running_corrects += torch.sum(torch.Tensor(preds) == torch.Tensor(labels))\n",
    "        total_num += inputs.size(0)\n",
    "\n",
    "    accuracy = running_corrects.double() / total_num\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_zsl(modelpath, loss, embedding_type, load_model_name, dataset_trained, csvfile, batch_size = 256):\n",
    "    \n",
    "    if dataset_trained == \"cifar10\" or dataset_trained==\"imagenetv2\":\n",
    "        print(\"Trained on cifar10, imagenetv2 ignoring\")\n",
    "        return\n",
    "    \n",
    "    if loss == \"cliplossv2\":\n",
    "        print(\"Cliploss v2\")\n",
    "        return\n",
    "    \n",
    "#     if loss == \"xeloss\":\n",
    "#         print(\"Xeloss\")\n",
    "#         return\n",
    "    \n",
    "    if load_model_name == \"beefyresnet\":\n",
    "        print(\"Beefy\")\n",
    "        return\n",
    "    \n",
    "    if (loss != \"xeloss\" and embedding_type == \"onehot\") or (loss == \"xeloss\" and embedding_type != \"onehot\"):\n",
    "        print(\"Not XELoss and onehot\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "#     print(modelpath)\n",
    "#     return\n",
    "    \n",
    "    dataset_label_sizes = {'imagenet':1000, 'imagenetv2': 1000, 'cifar10': 10, 'cifar100': 100, 'imagenetv2coarse': 1000,}\n",
    "\n",
    "    mean = {'cifar10': (0.4914, 0.4822, 0.4465), 'cifar100': (0.5071, 0.4867, 0.4408), 'cifar100super': (0.2675, 0.2565, 0.2761), 'imagenet':(0.485, 0.456, 0.406), 'imagenetv2': (0.485, 0.456, 0.406), 'imagenetv2coarse': (0.485, 0.456, 0.406)}\n",
    "    std  = {'cifar10': (0.2023, 0.1994, 0.2010), 'cifar100': (0.2675, 0.2565, 0.2761), 'cifar100super': (0.2675, 0.2565, 0.2761), 'imagenet':(0.229, 0.224, 0.225), 'imagenetv2': (0.229, 0.224, 0.225), 'imagenetv2coarse': (0.229, 0.224, 0.225)}\n",
    "    \n",
    "    if embedding_type == \"onehot\":\n",
    "        embedding_dim = dataset_label_sizes[dataset_trained]\n",
    "    else:\n",
    "        embedding_dim = 768\n",
    "        \n",
    "    zslmodel, input_size = initialize_model(load_model_name, embedding_dim, False, use_pretrained=True)\n",
    "    zslmodel.load_state_dict(torch.load(modelpath))\n",
    "    \n",
    "    # Detect if we have a GPU available\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using GPU? {torch.cuda.is_available()}\")\n",
    "    zslmodel = zslmodel.to(device)\n",
    "    zslmodel.eval()\n",
    "    \n",
    "#     datasets = [\"imagenetv2\", \"cifar10\", \"cifar100\", \"cifar100super\"]\n",
    "    datasets = [\"cifar100\"]\n",
    "\n",
    "    for dataset_name in datasets:\n",
    "#         if dataset_name = dataset_trained:\n",
    "#             continue\n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.RandomResizedCrop(input_size),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean[dataset_name], std[dataset_name])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize(input_size),\n",
    "                transforms.CenterCrop(input_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean[dataset_name], std[dataset_name])\n",
    "            ]),\n",
    "        }\n",
    "        \n",
    "        for embed_t in [\"clip\", \"label\", \"onehot\"]:\n",
    "#         for embed_t in [\"onehot\"]:\n",
    "            if loss == \"xeloss\" and embed_t != \"onehot\":\n",
    "                continue\n",
    "            if embed_t == \"onehot\" and loss != \"xeloss\":\n",
    "                continue\n",
    "            dataloader_dict = create_dataloaders(dataset_name, data_transforms, input_size, batch_size)\n",
    "\n",
    "            label_embeddings = generate_label_embeddings(embed_t, embedding_dim, dataset_name)\n",
    "\n",
    "            if label_embeddings is None:\n",
    "                continue\n",
    "\n",
    "            accuracy = zsl_test(zslmodel, dataloader_dict['val'], label_embeddings=label_embeddings, embedding_to_label=closest_labelembedding, morph_labels=morph_labels_cifar100)\n",
    "            \n",
    "            with open(csvfile, 'a') as f:\n",
    "                line = str(modelpath) + \", \" + str(loss) + \", \" + str(embedding_type)  + \", \" + str(load_model_name) + \", \" + str(dataset_trained) + \", \" + str(dataset_name) + \", \" + str(embed_t) + \", \" + str(accuracy.cpu().numpy()) + \"\\n\"\n",
    "                f.writelines(line)\n",
    "            print(dataset_name, embed_t, accuracy.cpu().numpy())\n",
    "        \n",
    "    del zslmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('./models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cliplossv2_wiki_verybeefyresnet_imagenetv2_256_adam_0.3355.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_verybeefyresnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.7491\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.7355\n",
      "\n",
      "\n",
      "cosineloss_clip_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_onehot_resnet_imagenetv2_256_adam_0.3915.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_onehot_resnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_resnet_imagenetv2_256_adam_0.1975.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_wiki_resnet_imagenetv2_256_adam_0.166.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_wiki_resnet_imagenetv2_256_adam_0.2145.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_clip_verybeefyresnet_cifar100_256_adam_final.mdl\n",
      "Cliploss v2\n",
      "\n",
      "\n",
      "cliplossv2_onehot_resnet_imagenetv2_256_adam_0.4015.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_label_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_verybeefyresnet_imagenetv2_256_adam_0.3275.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_beefyresnet_imagenetv2_256_adam_0.2755.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_onehot_verybeefyresnet_cifar10_256_adam_0.8253.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_clip_verybeefyresnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Cliploss v2\n",
      "\n",
      "\n",
      "cliploss_onehot_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_verybeefyresnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.6673\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.6891\n",
      "\n",
      "\n",
      "cliploss_wiki_beefyresnet_imagenetv2_256_adam_0.3005.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_onehot_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_onehot_beefyresnet_cifar10_256_adam_0.8235.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_verybeefyresnet_cifar10_256_adam_0.8140000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_resnet_imagenetv2_256_adam_0.4265.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_resnet_imagenetv2_256_adam_0.1955.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_resnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.5666\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.4583\n",
      "\n",
      "\n",
      "cliplossv2_clip_beefyresnet_cifar10_256_adam_0.8214.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_resnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.6371\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.521\n",
      "\n",
      "\n",
      "xeloss_onehot_verybeefyresnet_cifar10_256_adam_0.8203.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_resnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.4599\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.5605\n",
      "\n",
      "\n",
      "xeloss_onehot_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_verybeefyresnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.6923\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.6782\n",
      "\n",
      "\n",
      "cliploss_onehot_resnet_cifar10_256_adam_0.7578.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_label_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_wiki_beefyresnet_imagenetv2_256_adam_0.264.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_verybeefyresnet_cifar10_256_adam_0.8236.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_verybeefyresnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.7286\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.7441\n",
      "\n",
      "\n",
      "cliploss_label_beefyresnet_imagenetv2_256_adam_0.3015.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_clip_verybeefyresnet_cifar10_256_adam_0.8239000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_onehot_beefyresnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_verybeefyresnet_imagenetv2_256_adam_0.28400000000000003.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_wiki_resnet_imagenetv2_256_adam_0.2095.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_clip_resnet_cifar100_256_adam_final.mdl\n",
      "Cliploss v2\n",
      "\n",
      "\n",
      "cliploss_onehot_verybeefyresnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_clip_verybeefyresnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.6906\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.6414\n",
      "\n",
      "\n",
      "cliploss_clip_beefyresnet_cifar10_256_adam_0.8172.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_resnet_cifar10_256_adam_0.7441.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_resnet_cifar10_256_adam_0.7343000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_resnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.3814\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.4841\n",
      "\n",
      "\n",
      "cliplossv2_onehot_resnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_wiki_verybeefyresnet_imagenetv2_256_adam_0.3375.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_beefyresnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_resnet_imagenetv2_256_adam_0.114.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_beefyresnet_cifar10_256_adam_0.7768.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_resnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_clip_resnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.5791\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.4067\n",
      "\n",
      "\n",
      "cliplossv2_label_resnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Cliploss v2\n",
      "\n",
      "\n",
      "cosineloss_label_resnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.4493\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.5581\n",
      "\n",
      "\n",
      "cosineloss_clip_resnet_imagenetv2_256_adam_0.1015.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_onehot_verybeefyresnet_cifar10_256_adam_0.8230000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_onehot_verybeefyresnet_imagenetv2_256_adam_0.2675.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_resnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 onehot 0.6194\n",
      "\n",
      "\n",
      "cosineloss_label_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_onehot_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_clip_verybeefyresnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.744\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.7019\n",
      "\n",
      "\n",
      "cliploss_label_resnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.5253\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.6353\n",
      "\n",
      "\n",
      "cliplossv2_label_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_clip_beefyresnet_imagenetv2_256_adam_0.275.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_clip_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_clip_beefyresnet_imagenetv2_256_adam_0.28400000000000003.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_verybeefyresnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Cliploss v2\n",
      "\n",
      "\n",
      "cosineloss_onehot_verybeefyresnet_imagenetv2_256_adam_0.001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_clip_resnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Cliploss v2\n",
      "\n",
      "\n",
      "cliplossv2_label_verybeefyresnet_imagenetv2_256_adam_0.321.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_onehot_resnet_cifar10_256_adam_0.7582.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_verybeefyresnet_imagenetv2_256_adam_0.3345.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_clip_resnet_imagenetv2_256_adam_0.1985.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_onehot_resnet_cifar10_256_adam_0.7565000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_onehot_beefyresnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_clip_verybeefyresnet_cifar10_256_adam_0.8238000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_beefyresnet_cifar10_256_adam_0.8204.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_onehot_beefyresnet_cifar10_256_adam_0.8158000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_resnet_cifar10_256_adam_0.7601.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_onehot_beefyresnet_imagenetv2_256_adam_0.3345.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_clip_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_onehot_beefyresnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_verybeefyresnet_cifar10_256_adam_0.8156.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_verybeefyresnet_imagenetv2_256_adam_0.329.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_clip_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_beefyresnet_cifar10_256_adam_0.8239000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_verybeefyresnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_verybeefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_wiki_verybeefyresnet_imagenetv2_256_adam_0.3315.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_verybeefyresnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 onehot 0.6884\n",
      "\n",
      "\n",
      "cliploss_label_verybeefyresnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.6706\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.6927\n",
      "\n",
      "\n",
      "cliplossv2_clip_verybeefyresnet_imagenetv2_256_adam_0.3355.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_onehot_verybeefyresnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_onehot_verybeefyresnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_clip_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_wiki_beefyresnet_imagenetv2_256_adam_0.3015.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_onehot_beefyresnet_cifar10_256_adam_0.8214.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_clip_beefyresnet_imagenetv2_256_adam_0.3025.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_resnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_onehot_beefyresnet_imagenetv2_256_adam_0.366.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "xeloss_label_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_resnet_cifar100_256_adam_final.mdl\n",
      "Cliploss v2\n",
      "\n",
      "\n",
      "cliplossv2_onehot_verybeefyresnet_cifar10_256_adam_0.8260000000000001.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_beefyresnet_imagenetv2_256_adam_0.2895.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_onehot_beefyresnet_imagenetv2_256_adam_0.3345.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliplossv2_label_verybeefyresnet_cifar100_256_adam_final.mdl\n",
      "Cliploss v2\n",
      "\n",
      "\n",
      "cosineloss_clip_verybeefyresnet_imagenetv2_256_adam_0.3235.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_onehot_resnet_imagenetv2_256_adam_0.3975.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_beefyresnet_cifar10_256_adam_0.8153.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_resnet_cifar10_256_adam_0.7409.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_onehot_resnet_imagenetv2_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cliploss_label_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_label_verybeefyresnet_imagenetv2cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.724\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.7455\n",
      "\n",
      "\n",
      "xeloss_clip_beefyresnet_cifar10_256_adam.mdl\n",
      "Trained on cifar10, imagenetv2 ignoring\n",
      "\n",
      "\n",
      "cosineloss_clip_resnet_cifar100_256_adam_final.mdl\n",
      "Using GPU? True\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 clip 0.5093\n",
      "Initializing Datasets and Dataloaders...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "cifar100 label 0.3535\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# csvfile = 'zslresults2.csv'\n",
    "csvfile = 'zsl_cifar100coarse.csv'\n",
    "with open(csvfile, 'w') as f:\n",
    "    f.writelines(\"modelpath, loss, train_embedding, model_type, train_dataset, zsldataset, zslembedding, accuracy\\n\")\n",
    "for i in files:\n",
    "    props = i.split(\"_\")\n",
    "    loss, embed, model_name, dataset = props[:4]\n",
    "    modelpath = './models/' + str(i)\n",
    "    print(i)\n",
    "#     try:\n",
    "    zslmodel = evaluate_zsl(modelpath, loss, embed, model_name, dataset, csvfile)\n",
    "#     except:\n",
    "#         print(\"Model failing to load\")\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cs290]",
   "language": "python",
   "name": "conda-env-cs290-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
